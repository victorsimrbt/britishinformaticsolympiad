#!/bin/bash
# Shedule execution of many runs
# Run from root folder with: bash bash/schedule.sh

# youtube
USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/avspeech-train/avspeech-train.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/youtube/best.ckpt
USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/avspeech-train/avspeech-train.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/youtube/best.ckpt



USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing youtube model on hdtf" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/hdtf-training/hdtf.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/youtube/best.ckpt



USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing youtube model on lrs2" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/lrs2/lrs2.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/youtube/best.ckpt

# lrs2

USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing lrs2 model on youtube" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/youtube-hq/hq.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/lrs/best.ckpt



USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing lrs2 model on avspeech" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/avspeech-train/avspeech-train.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/lrs/best.ckpt



USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="testing lrs2 model on hdtf" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/hdtf-training/hdtf.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/lrs/best.ckpt

# avspeech

USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="avspeech model on youtube" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/youtube-hq/hq.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/avspeech/best.ckpt


USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="avspeech model on hdtf" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/hdtf-training/hdtf.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/avspeech/best.ckpt

USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="avspeech model on lrs2" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/lrs2/lrs2.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/avspeech/best.ckpt

#hdtf

USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="hdtf model on lrs2" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/lrs2/lrs2.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/hdtf/best.ckpt

USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="hdtf model on youtube" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/youtube-hq/hq.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/hdtf/best.ckpt

USER=victor python run.py experiment=lip_sync_discriminator/train_sync_discriminator.yaml model/sync_discriminator@model.video_encoder=adversarial_video_encoder.yaml callbacks.model_checkpoint.every_n_train_steps=20000 callbacks.model_checkpoint.dirpath=ckpts/SyncDis trainer.progress_bar_refresh_rate=1 trainer.log_every_n_steps=500 trainer.weights_summary=top trainer.accelerator=null trainer.profiler=null datamodule.train.dataloader.batch_size=100 datamodule.val.dataloader.batch_size=100 datamodule.val.dataloader.num_workers=10 model.audio_encoder.c=[512,512,512] model.audio_encoder.use_linear_for_audio=false +model.audio_encoder.group_norm=true model.video_encoder.image_encoder.activation_norm_type=layer_2d model.video_encoder.image_encoder.weight_norm_type=spectral model.img_logs=[] model.curves=[] model.losses.cosine_loss=0 model.losses.cosine_loss_strict=0 model.losses.raw_cosine_loss=0 model.losses.cosine_loss_hinge=1 trainer.num_sanity_val_steps=0 ignore_warnings=false +logger.wandb.notes="hdtf model on avspeech" train=false test=true +datamodule.test.dataset.path=/data/audiovisual/training/avspeech-train/avspeech-train.zarr +datamodule.test.dataset.img_seq_len=5 +datamodule.test.dataset.quiet=false +datamodule.test.dataset.force_reindex=false +datamodule.test.dataset.subsample=null +test_ckpt=/home/guillaume/AIDOL/ckpts/hdtf/best.ckpt